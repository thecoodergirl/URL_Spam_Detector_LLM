# -*- coding: utf-8 -*-
"""url_detector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kSepa_WcSfwI9I_2J5jNMRMSmK5jzTtw
"""

!pip install datasets
!pip install transformers
!pip install accelerate -U
from typing import Optional, Union
import pandas as pd
import numpy as np
import torch
from datasets import Dataset
from dataclasses import dataclass
from transformers import AutoTokenizer
from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy
from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, AutoModel

deberta_v3_large = '/kaggle/input/deberta-v3-large-hf-weights'

"""We begin by loading and processing the train data."""

import pandas as pd

# Read the CSV file into a pandas DataFrame
df_train = pd.read_csv('/content/dataset_phishing.csv')
df_train

"""Let's add another 500 examples to the train set!"""

from transformers import DistilBertTokenizer

# Load the DistilBERT tokenizer
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')

# Tokenize the email texts and prepare the input tensors
tokenized_texts = tokenizer(df_train['url'].tolist(), padding='max_length', truncation=True, max_length=128, return_tensors='pt')

# Assuming you have labels in the 'label' column, convert labels to numerical format
label_mapping = {"legitimate": 0, "phishing": 1}
labels = [label_mapping[label] for label in df_train['status']]

# Create a PyTorch Dataset
from torch.utils.data import Dataset, DataLoader, random_split

class EmailDataset(Dataset):
    def __init__(self, tokenized_texts, labels):
        self.tokenized_texts = tokenized_texts
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        return {
            'input_ids': self.tokenized_texts['input_ids'][idx],
            'attention_mask': self.tokenized_texts['attention_mask'][idx],
            'labels': self.labels[idx]
        }

"""Now that we have gone from 200 -> 700 train examples, let us preprocess the data and begin training."""

# Create the dataset
email_dataset = EmailDataset(tokenized_texts, labels)

# Split the dataset into train and validation sets
train_size = int(0.8 * len(email_dataset))
val_size = len(email_dataset) - train_size
train_dataset, val_dataset = random_split(email_dataset, [train_size, val_size])

"""We first create a HuggingFace `Dataset`."""

# Create DataLoader instances
batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size)

"""And let us now preprocess the examples for training."""

# Import necessary components for transfer learning
from transformers import DistilBertForSequenceClassification, AdamW

# Load the pre-trained DistilBERT model for sequence classification
model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

# Set up the optimizer
optimizer = AdamW(model.parameters(), lr=1e-5)

!pip install accelerate -U

# Set up the training arguments
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,   # Adjust the number of epochs as needed
    per_device_train_batch_size=batch_size,
    per_device_eval_batch_size=batch_size,
    logging_dir='./logs',
)

# Create the Trainer instance for training
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
)

# Fine-tune the model on your email dataset
trainer.train()

# Evaluate the model
results = trainer.evaluate()

print(results)  # Print evaluation results

import os
print(os.getcwd())
# Save the trained model
saved_model = model.save_pretrained('./content/')



"""Now that we have trained our model, let us predict on the test set."""



import torch
from transformers import DistilBertForSequenceClassification, DistilBertTokenizer

# Load the fine-tuned model from the saved location
model = DistilBertForSequenceClassification.from_pretrained('./content/')

# Load the DistilBERT tokenizer
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')

# Put the model in evaluation mode
model.eval()

while True:
    url = input("Enter a URL (or type 'exit' to quit): ")

    if url.lower() == 'exit':
        break

    # Tokenize the input URL and prepare the input tensors
    tokenized_input = tokenizer(url, padding='max_length', truncation=True, max_length=128, return_tensors='pt')
    input_ids = tokenized_input['input_ids'].to(model.device)
    attention_mask = tokenized_input['attention_mask'].to(model.device)

    # Forward pass through the model
    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        predicted_label = torch.argmax(outputs.logits, dim=1).item()

    predicted_status = "legitimate" if predicted_label == 0 else "phishing"
    print(f"The predicted status for the URL '{url}' is: {predicted_status}")



"""# New Section"""

import os
print(os.getcwd())

from google.colab import drive
drive.mount('/content/drive')

import torch
from transformers import DistilBertForSequenceClassification, DistilBertTokenizer

class URLPredictor:
    def __init__(self, model_path):
        self.model = DistilBertForSequenceClassification.from_pretrained(model_path)
        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
        self.model.eval()

    def predict_url(self, url):
        tokenized_input = self.tokenizer(url, padding='max_length', truncation=True, max_length=128, return_tensors='pt')
        input_ids = tokenized_input['input_ids'].to(self.model.device)
        attention_mask = tokenized_input['attention_mask'].to(self.model.device)

        with torch.no_grad():
            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)
            predicted_label = torch.argmax(outputs.logits, dim=1).item()

        predicted_status = "legitimate" if predicted_label == 0 else "phishing"
        return predicted_status

if __name__ == "__main__":
    model_path = './content/'  # Set your model path here
    url_predictor = URLPredictor(model_path)

    while True:
        url = input("Enter a URL (or type 'exit' to quit): ")

        if url.lower() == 'exit':
            break

        predicted_status = url_predictor.predict_url(url)
        print(f"The predicted status for the URL '{url}' is: {predicted_status}")

!pip install streamlit

import torch
from transformers import DistilBertForSequenceClassification, DistilBertTokenizer
import gradio as gr

class URLPredictor:
    def __init__(self, model_path):
        self.model = DistilBertForSequenceClassification.from_pretrained(model_path)
        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
        self.model.eval()

    def predict_url(self, url):
        tokenized_input = self.tokenizer(url, padding='max_length', truncation=True, max_length=128, return_tensors='pt')
        input_ids = tokenized_input['input_ids'].to(self.model.device)
        attention_mask = tokenized_input['attention_mask'].to(self.model.device)

        with torch.no_grad():
            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)
            predicted_label = torch.argmax(outputs.logits, dim=1).item()

        predicted_status = "legitimate" if predicted_label == 0 else "phishing"
        return predicted_status

# Create a Gradio interface
def gr_predict_url(url):
    predicted_status = url_predictor.predict_url(url)
    return f"The predicted status for the URL '{url}' is: {predicted_status}"

url_predictor = URLPredictor('./content/')  # Initialize the URLPredictor instance

iface = gr.Interface(fn=gr_predict_url, inputs="text", outputs="text",
                     title="URL Phishing Predictor",
                     description="Enter a URL to predict if it's legitimate or phishing.")
iface.launch()

import streamlit as st
import torch
from transformers import DistilBertForSequenceClassification, DistilBertTokenizer

class URLPredictor:
    def __init__(self, model_path):
        self.model = DistilBertForSequenceClassification.from_pretrained(model_path)
        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
        self.model.eval()

    def predict_url(self, url):
        tokenized_input = self.tokenizer(url, padding='max_length', truncation=True, max_length=128, return_tensors='pt')
        input_ids = tokenized_input['input_ids'].to(self.model.device)
        attention_mask = tokenized_input['attention_mask'].to(self.model.device)

        with torch.no_grad():
            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)
            predicted_label = torch.argmax(outputs.logits, dim=1).item()

        predicted_status = "legitimate" if predicted_label == 0 else "phishing"
        return predicted_status

# Create a Streamlit app
def streamlit_app():
    st.title("URL Phishing Predictor")
    st.write("Enter a URL to predict if it's legitimate or phishing.")

    url = st.text_input("Enter a URL:")

    if url:
        url_predictor = URLPredictor('./content/')  # Initialize the URLPredictor instance
        predicted_status = url_predictor.predict_url(url)
        st.write(f"The predicted status for the URL '{url}' is: {predicted_status}")

if __name__ == "__main__":
    streamlit_app()